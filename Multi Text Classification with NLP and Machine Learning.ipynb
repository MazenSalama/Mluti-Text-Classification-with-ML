{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mazensalama/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Load EDA Pkgs\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Visualization Pkgs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML Pkgs\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find All Dataset from CSV\n",
    "path = os.path.join(\"CSV\")\n",
    "all_files = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load All Dataset at once\n",
    "all_df = pd.concat((pd.read_csv(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Personal</th>\n",
       "      <th>LOR</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MEDICAL STUDENT PERFORMANCE EVALUATI...</td>\n",
       "      <td>Language FluencyLanguageLanguage ProficiencyPr...</td>\n",
       "      <td>Swift-Taylor, Mary Elizabeth (12968494)07/11/2...</td>\n",
       "      <td>MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Appendix E !Medical School Information Keck Sc...</td>\n",
       "      <td>MEDICAL STUDENT PERFORMANCE EVALUATI...</td>\n",
       "      <td>I(eck School of MedicineDepartment of Pediatri...</td>\n",
       "      <td>MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Moore, Morgan (13224044)MyERAS ApplicationUniv...</td>\n",
       "      <td>Moore, Morgan (13224044)MyERAS ApplicationUniv...</td>\n",
       "      <td>Moore, Morgan (13224044)LoR - Rebecca LatchUni...</td>\n",
       "      <td>MMoore_13224044_b74fd233-f414-4d19-bd6b-422581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Moore, Morgan (13224044)MyERAS ApplicationUniv...</td>\n",
       "      <td>Moore, Morgan (13224044)MSPEUniversity of Utah...</td>\n",
       "      <td>Moore, Morgan (13224044)LoR - Rebecca LatchUni...</td>\n",
       "      <td>MMoore_13224044_b74fd233-f414-4d19-bd6b-422581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Moore, Morgan (13224044)Curriculum VitaeUniver...</td>\n",
       "      <td>Moore, Morgan (13224044)MSPEUniversity of Utah...</td>\n",
       "      <td>Moore, Morgan (13224044)LoR - Lanessa BassUniv...</td>\n",
       "      <td>MMoore_13224044_b74fd233-f414-4d19-bd6b-422581...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                         Experience  \\\n",
       "0          0            MEDICAL STUDENT PERFORMANCE EVALUATI...   \n",
       "1          1  Appendix E !Medical School Information Keck Sc...   \n",
       "0          0  Moore, Morgan (13224044)MyERAS ApplicationUniv...   \n",
       "1          1  Moore, Morgan (13224044)MyERAS ApplicationUniv...   \n",
       "2          2  Moore, Morgan (13224044)Curriculum VitaeUniver...   \n",
       "\n",
       "                                            Personal  \\\n",
       "0  Language FluencyLanguageLanguage ProficiencyPr...   \n",
       "1            MEDICAL STUDENT PERFORMANCE EVALUATI...   \n",
       "0  Moore, Morgan (13224044)MyERAS ApplicationUniv...   \n",
       "1  Moore, Morgan (13224044)MSPEUniversity of Utah...   \n",
       "2  Moore, Morgan (13224044)MSPEUniversity of Utah...   \n",
       "\n",
       "                                                 LOR  \\\n",
       "0  Swift-Taylor, Mary Elizabeth (12968494)07/11/2...   \n",
       "1  I(eck School of MedicineDepartment of Pediatri...   \n",
       "0  Moore, Morgan (13224044)LoR - Rebecca LatchUni...   \n",
       "1  Moore, Morgan (13224044)LoR - Rebecca LatchUni...   \n",
       "2  Moore, Morgan (13224044)LoR - Lanessa BassUniv...   \n",
       "\n",
       "                                           File_Name  \n",
       "0  MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...  \n",
       "1  MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...  \n",
       "0  MMoore_13224044_b74fd233-f414-4d19-bd6b-422581...  \n",
       "1  MMoore_13224044_b74fd233-f414-4d19-bd6b-422581...  \n",
       "2  MMoore_13224044_b74fd233-f414-4d19-bd6b-422581...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1873, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df[[ 'File_Name','Experience', 'Personal', 'LOR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save All Combined Dataset\n",
    "all_df.to_csv(\"All_Combined_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Dataset to Have A Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df = all_df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  File_Name     MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...\n",
       "   Experience              MEDICAL STUDENT PERFORMANCE EVALUATI...\n",
       "   Personal      Language FluencyLanguageLanguage ProficiencyPr...\n",
       "   LOR           Swift-Taylor, Mary Elizabeth (12968494)07/11/2...\n",
       "1  File_Name     MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index\n",
    "new_df = stacked_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'level_1', 0], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(columns={'level_0':'FileID','level_1':'Target',0:'Details'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>File_Name</td>\n",
       "      <td>MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Experience</td>\n",
       "      <td>MEDICAL STUDENT PERFORMANCE EVALUATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Language FluencyLanguageLanguage ProficiencyPr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LOR</td>\n",
       "      <td>Swift-Taylor, Mary Elizabeth (12968494)07/11/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>File_Name</td>\n",
       "      <td>MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FileID      Target                                            Details\n",
       "0       0   File_Name  MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98...\n",
       "1       0  Experience            MEDICAL STUDENT PERFORMANCE EVALUATI...\n",
       "2       0    Personal  Language FluencyLanguageLanguage ProficiencyPr...\n",
       "3       0         LOR  Swift-Taylor, Mary Elizabeth (12968494)07/11/2...\n",
       "4       1   File_Name  MSwift-Taylor_12968494_6406f0d8-ecf3-497e-9e98..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = new_df[new_df['Target'] != 'File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Dataset\n",
    "new_df1.to_csv(\"Main_Reshaped_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"Main_Reshaped_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FileID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Experience</td>\n",
       "      <td>MEDICAL STUDENT PERFORMANCE EVALUATI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Language FluencyLanguageLanguage ProficiencyPr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>LOR</td>\n",
       "      <td>Swift-Taylor, Mary Elizabeth (12968494)07/11/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Experience</td>\n",
       "      <td>Appendix E !Medical School Information Keck Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal</td>\n",
       "      <td>MEDICAL STUDENT PERFORMANCE EVALUATI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  FileID      Target  \\\n",
       "0           1       0  Experience   \n",
       "1           2       0    Personal   \n",
       "2           3       0         LOR   \n",
       "3           5       1  Experience   \n",
       "4           6       1    Personal   \n",
       "\n",
       "                                             Details  \n",
       "0            MEDICAL STUDENT PERFORMANCE EVALUATI...  \n",
       "1  Language FluencyLanguageLanguage ProficiencyPr...  \n",
       "2  Swift-Taylor, Mary Elizabeth (12968494)07/11/2...  \n",
       "3  Appendix E !Medical School Information Keck Sc...  \n",
       "4            MEDICAL STUDENT PERFORMANCE EVALUATI...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of Dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience    1873\n",
       "LOR           1873\n",
       "Personal      1873\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Counts of Each Labels\n",
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1d07e860>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2664x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(df.Details)\n",
    "word_freq = dict(zip(cv.get_feature_names(), np.asarray(bow.sum(axis=0)).ravel()))\n",
    "word_counter = collections.Counter(word_freq)\n",
    "word_counter_df = pd.DataFrame(word_counter.most_common(20), columns = ['word', 'freq'])\n",
    "fig, ax = plt.subplots(figsize=(37, 15))\n",
    "sns.barplot(x=\"word\", y=\"freq\", data=word_counter_df, palette=\"PuBuGn_d\", ax=ax)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Experience', 'Personal', 'LOR'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding Target Column\n",
    "+ Experience = 1\n",
    "+ Personal = 2\n",
    "+ LOR = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode Target Column\n",
    "df['Class'] = df['Target'].map({'Experience':1, 'Personal':2, 'LOR':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    1\n",
       "4    2\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mazensalama/anaconda3/lib/python3.7/site-packages/seaborn/categorical.py:3666: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n",
      "  warnings.warn(msg)\n",
      "/Users/mazensalama/anaconda3/lib/python3.7/site-packages/seaborn/categorical.py:3672: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visually the new aggregated column\n",
    "sns.factorplot(x=\"Class\", data=df, kind=\"count\", size=6, aspect=1.5, palette=\"PuBuGn_d\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mazensalama/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load NLP Pkgs\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of stop words and adding custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "##Creating a list of custom stopwords\n",
    "new_words = ['MyERAS',\n",
    "             'Application',\n",
    "             'University',\n",
    "             'Utah',\n",
    "             'Program',\n",
    "             'Page',\n",
    "             'ERAS',\n",
    "             'Confidential',\n",
    "             'Do not disclose',\n",
    "             'distribute',\n",
    "             'applicant',\n",
    "             'information',\n",
    "             'persons',\n",
    "             'outside',\n",
    "             'application process']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True,stop_words=stopwords,ngram_range = (1,1),tokenizer = token.tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "Ylabels = df['Class']\n",
    "Xfeatures = df['Details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(Xfeatures, Ylabels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['Details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df['Details'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df['Details'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(df['Details'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to Train Model,Save Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(classifier,feature_vector_train,label,model_filename):\n",
    "    classifier.fit(feature_vector_train,label)\n",
    "    save_model_file = '{}_model.pkl'.format(model_filename)\n",
    "    joblib.dump(classifier, save_model_file)\n",
    "    print(\"Saved model as {}\".format(save_model_file))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Naive Bayes with Count Vectors\n",
    "+ Naive bayes is a classification algorithm\n",
    "+ It is based on the Bayes Theorem with an assumption of independence among #predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.7265717674970344\n",
      "NB, WordLevel TF-IDF:  0.732502965599051\n",
      "NB, N-Gram Vectors:  0.7348754448398577\n",
      "NB, CharLevel Vectors:  0.6927639383155397\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Logistic Regression\n",
    "+ Logistic regression measures the relationship between the categorical dependent variable and one or more independent \n",
    "+ Variables by estimating probabilities using a logistic/sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mazensalama/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/mazensalama/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.7295373665480427\n",
      "LR, WordLevel TF-IDF:  0.7502965599051008\n",
      "LR, N-Gram Vectors:  0.7568208778173191\n",
      "LR, CharLevel Vectors:  0.7627520759193357\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Joblib to Save Model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model as logiticRegression_CountVectors_model.pkl\n",
      "Saved model as logiticRegression_TF_IDF_model.pkl\n",
      "Saved model as logiticRegression_CharLevel_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Linear Classifier on Word Level TF IDF Vectors\n",
    "save_models(linear_model.LogisticRegression(),xtrain_tfidf, train_y,\"logiticRegression_CountVectors\")\n",
    "\n",
    "# Save Linear Classifier on Ngram Level TF IDF Vectors\n",
    "save_models(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y,\"logiticRegression_TF_IDF\")\n",
    "\n",
    "\n",
    "# Save Linear Classifier on Character Level TF IDF Vectors\n",
    "save_models(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y,\"logiticRegression_CharLevel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.3262158956109134\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting Models and Tree Based Algorithms\n",
    "+ RandomForest\n",
    "+ XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, ensemble\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.6957295373665481\n",
      "RF, WordLevel TF-IDF:  0.7147093712930012\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting -XGBoost Classifier\n",
    "+ Boosting models are another type of ensemble models part of tree based models. \n",
    "+ Boosting is a machine learning #\n",
    "+ ensemble meta-algorithm to reduce bias, and also variance in supervised learning, \n",
    "+ It is a family of machine learning algorithms that convert weak learners to strong ones.\n",
    "+ A weak learner is defined to be a classifier that is only slightly correlated with the true classification (it can label examples better than random guessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors:  0.8143534994068802\n",
      "Xgb, WordLevel TF-IDF:  0.8072360616844603\n",
      "Xgb, CharLevel Vectors:  0.7841043890865955\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print (\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print (\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print (\"Xgb, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model as Extereme Gradient Boosting on Count Vectors_model.pkl\n",
      "Saved model as Extereme Gradient Boosting on Word Level TF IDF Vectors_model.pkl\n",
      "Saved model as Extereme Gradient Boosting on Character Level TF IDF Vectors_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Extereme Gradient Boosting on Count Vectors\n",
    "save_models(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y,\"Extereme Gradient Boosting on Count Vectors\")\n",
    "\n",
    "# Save Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "save_models(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y,\"Extereme Gradient Boosting on Word Level TF IDF Vectors\")\n",
    "\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "save_models(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, \"Extereme Gradient Boosting on Character Level TF IDF Vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostic Performance of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of the Terms:\n",
    "Class Statistics:\n",
    "\n",
    "+ Classes                                       \n",
    "+ Population                                    \n",
    "+ P: Condition positive                          \n",
    "+ N: Condition negative                          \n",
    "+ Test outcome positive                          \n",
    "+ Test outcome negative                          \n",
    "+ TP: True Positive                              \n",
    "+ TN: True Negative                              \n",
    "+ FP: False Positive                             \n",
    "+ FN: False Negative                             \n",
    "+ TPR: (Sensitivity, hit rate, recall)           \n",
    "+ TNR=SPC: (Specificity)                 \n",
    "+ PPV: Pos Pred Value (Precision)              \n",
    "+ NPV: Neg Pred Value                            \n",
    "+ FPR: False-out                         \n",
    "+ FDR: False Discovery Rate                    \n",
    "+ FNR: Miss Rate                                 \n",
    "+ ACC: Accuracy                          \n",
    "+ F1 score                                    \n",
    "+ MCC: Matthews correlation coefficient  \n",
    "+ Informedness                           \n",
    "+ Markedness                                   \n",
    "+ Prevalence                                  \n",
    "+ LR+: Positive likelihood ratio               \n",
    "+ LR-: Negative likelihood ratio                 \n",
    "+ DOR: Diagnostic odds ratio                   \n",
    "+ FOR: False omission rate                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "\n",
    "##### The diagnostic measures covered  for High Accuracutre ML Model are:\n",
    "+ 1) accuracy: proportion of test results that are correct\n",
    "+ 2) sensitivity: proportion of true +ve identified\n",
    "+ 3) specificity: proportion of true -ve identified\n",
    "+ 4) positive likelihood: increased probability of true +ve if test +ve\n",
    "+ 5) negative likelihood: reduced probability of true +ve if test -ve\n",
    "+ 6) false positive rate: proportion of false +ves in true -ve patients\n",
    "+ 7) false negative rate: proportion of false -ves in true +ve patients\n",
    "+ 8) positive predictive value: chance of true +ve if test +ve\n",
    "+ 9) negative predictive value: chance of true -ve if test -ve\n",
    "+ 10) precision = positive predictive value\n",
    "+ 11) recall = sensitivity\n",
    "+ 12) f1 = (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pandas ML\n",
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Check For Performance \n",
    "def check_model_performance(classifier, feature_vector_train, label, feature_vector_test,label_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    y_predictions = classifier.predict(feature_vector_test)\n",
    "    our_confusion_matrix = ConfusionMatrix(label_test,y_predictions)\n",
    "    print(our_confusion_matrix.print_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1    2  __all__\n",
      "Actual                           \n",
      "0          397  126   41      564\n",
      "1          152  358   50      560\n",
      "2           35   37  490      562\n",
      "__all__    584  521  581     1686\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.7384341637010676\n",
      "95% CI: (0.7167561387957921, 0.7592790388849464)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 3.446696786439726e-236\n",
      "Kappa: 0.6076251571291514\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       0         1          2\n",
      "Population                                 1686      1686       1686\n",
      "P: Condition positive                       564       560        562\n",
      "N: Condition negative                      1122      1126       1124\n",
      "Test outcome positive                       584       521        581\n",
      "Test outcome negative                      1102      1165       1105\n",
      "TP: True Positive                           397       358        490\n",
      "TN: True Negative                           935       963       1033\n",
      "FP: False Positive                          187       163         91\n",
      "FN: False Negative                          167       202         72\n",
      "TPR: (Sensitivity, hit rate, recall)   0.703901  0.639286   0.871886\n",
      "TNR=SPC: (Specificity)                 0.833333   0.85524   0.919039\n",
      "PPV: Pos Pred Value (Precision)        0.679795   0.68714   0.843373\n",
      "NPV: Neg Pred Value                    0.848457  0.826609   0.934842\n",
      "FPR: False-out                         0.166667   0.14476  0.0809609\n",
      "FDR: False Discovery Rate              0.320205   0.31286   0.156627\n",
      "FNR: Miss Rate                         0.296099  0.360714   0.128114\n",
      "ACC: Accuracy                          0.790036  0.783511   0.903321\n",
      "F1 score                               0.691638   0.66235   0.857393\n",
      "MCC: Matthews correlation coefficient  0.532724  0.504046   0.784544\n",
      "Informedness                           0.537234  0.494526   0.790925\n",
      "Markedness                             0.528252   0.51375   0.778215\n",
      "Prevalence                              0.33452  0.332147   0.333333\n",
      "LR+: Positive likelihood ratio           4.2234   4.41617    10.7692\n",
      "LR-: Negative likelihood ratio         0.355319   0.42177     0.1394\n",
      "DOR: Diagnostic odds ratio              11.8862   10.4706    77.2543\n",
      "FOR: False omission rate               0.151543  0.173391  0.0651584\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# For Linear Classifier on Count Vectors\n",
    "check_model_performance(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count,valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1    2  __all__\n",
      "Actual                           \n",
      "0          437   87   40      564\n",
      "1          215  291   54      560\n",
      "2           27   20  515      562\n",
      "__all__    679  398  609     1686\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.7372479240806643\n",
      "95% CI: (0.7155414108630261, 0.7581254544759766)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0830652730727934e-170\n",
      "Kappa: 0.6057549688519728\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       0          1          2\n",
      "Population                                 1686       1686       1686\n",
      "P: Condition positive                       564        560        562\n",
      "N: Condition negative                      1122       1126       1124\n",
      "Test outcome positive                       679        398        609\n",
      "Test outcome negative                      1007       1288       1077\n",
      "TP: True Positive                           437        291        515\n",
      "TN: True Negative                           880       1019       1030\n",
      "FP: False Positive                          242        107         94\n",
      "FN: False Negative                          127        269         47\n",
      "TPR: (Sensitivity, hit rate, recall)   0.774823   0.519643    0.91637\n",
      "TNR=SPC: (Specificity)                 0.784314   0.904973    0.91637\n",
      "PPV: Pos Pred Value (Precision)        0.643594   0.731156   0.845649\n",
      "NPV: Neg Pred Value                    0.873883   0.791149    0.95636\n",
      "FPR: False-out                         0.215686  0.0950266  0.0836299\n",
      "FDR: False Discovery Rate              0.356406   0.268844   0.154351\n",
      "FNR: Miss Rate                         0.225177   0.480357  0.0836299\n",
      "ACC: Accuracy                          0.781139   0.776987    0.91637\n",
      "F1 score                               0.703138   0.607516    0.87959\n",
      "MCC: Matthews correlation coefficient  0.537903   0.470934    0.81723\n",
      "Informedness                           0.559136   0.424616    0.83274\n",
      "Markedness                             0.517476   0.522305   0.802009\n",
      "Prevalence                              0.33452   0.332147   0.333333\n",
      "LR+: Positive likelihood ratio          3.59236    5.46839    10.9574\n",
      "LR-: Negative likelihood ratio         0.287101   0.530797  0.0912621\n",
      "DOR: Diagnostic odds ratio              12.5125    10.3022    120.066\n",
      "FOR: False omission rate               0.126117   0.208851  0.0436397\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# For Naive Bayes Classifier on Count Vectors\n",
    "check_model_performance(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count,valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1    2  __all__\n",
      "Actual                           \n",
      "0          440   80   44      564\n",
      "1          111  402   47      560\n",
      "2           26   27  509      562\n",
      "__all__    577  509  600     1686\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.8013048635824437\n",
      "95% CI: (0.7814445692989914, 0.8201103905490197)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 2.1390224320863164e-307\n",
      "Kappa: 0.701935904688727\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       0          1          2\n",
      "Population                                 1686       1686       1686\n",
      "P: Condition positive                       564        560        562\n",
      "N: Condition negative                      1122       1126       1124\n",
      "Test outcome positive                       577        509        600\n",
      "Test outcome negative                      1109       1177       1086\n",
      "TP: True Positive                           440        402        509\n",
      "TN: True Negative                           985       1019       1033\n",
      "FP: False Positive                          137        107         91\n",
      "FN: False Negative                          124        158         53\n",
      "TPR: (Sensitivity, hit rate, recall)   0.780142   0.717857   0.905694\n",
      "TNR=SPC: (Specificity)                 0.877897   0.904973   0.919039\n",
      "PPV: Pos Pred Value (Precision)        0.762565   0.789784   0.848333\n",
      "NPV: Neg Pred Value                    0.888188    0.86576   0.951197\n",
      "FPR: False-out                         0.122103  0.0950266  0.0809609\n",
      "FDR: False Discovery Rate              0.237435   0.210216   0.151667\n",
      "FNR: Miss Rate                         0.219858   0.282143   0.094306\n",
      "ACC: Accuracy                          0.845196   0.842823   0.914591\n",
      "F1 score                               0.771253   0.752105   0.876076\n",
      "MCC: Matthews correlation coefficient  0.654385   0.638978   0.812034\n",
      "Informedness                           0.658038    0.62283   0.824733\n",
      "Markedness                             0.650753   0.655544    0.79953\n",
      "Prevalence                              0.33452   0.332147   0.333333\n",
      "LR+: Positive likelihood ratio          6.38919    7.55427    11.1868\n",
      "LR-: Negative likelihood ratio         0.250437   0.311769   0.102614\n",
      "DOR: Diagnostic odds ratio              25.5121    24.2303    109.019\n",
      "FOR: False omission rate               0.111812    0.13424  0.0488029\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# For Extereme Gradient Boosting on Count Vectors\n",
    "check_model_performance(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc(),valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Deep Learning Models\n",
    "+ Deep Neural Networks\n",
    "+ Convolutional Neural Network\n",
    "+ RNN - Long Short Term Memory(LSTM)\n",
    "+ RCNN - Recurrent Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallow Neural Networks\n",
    "+ Neural network is a mathematical model that is designed to behave similar to biological neurons and the nervous system. \n",
    "\n",
    "+ These models are used to recognize complex patterns and relationships that exists within a labelled data.\n",
    "\n",
    "+ The shallow neural network contains mainly three types of layers \n",
    "\n",
    " - Input layer\n",
    "\n",
    " - Hidden layer\n",
    " \n",
    " - Output layer\n",
    "\n",
    "#### Deep Neural Networks\n",
    "\n",
    "+ Deep Neural Networks are more complex neural networks in which the hidden layers performs extrem and \n",
    "+ more complex operations than the simple sigmoid or relu activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load DL Pkgs\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Input\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "#300d-1M.vec\n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(df['Details'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_architecture(input_size):\n",
    "    # create input layer \n",
    "    input_layer = layers.Input((input_size, ), sparse=True)\n",
    "    \n",
    "    # create hidden layer\n",
    "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    # create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    classifier = models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    return classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-b07b2fb19559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_tfidf_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtrain_tfidf_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxvalid_tfidf_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_neural_net\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"NN, Ngram Level TF IDF Vectors\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-80ae62c3045c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vector_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vector_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_neural_net\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# fit the training dataset on the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# predict the labels on validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3275\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[0;32m-> 3277\u001b[0;31m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "accuracy = train_model(classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, is_neural_net=True)\n",
    "print (\"NN, Ngram Level TF IDF Vectors\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Deep Learning Model\n",
    "+ In the Convolutional neural networks, convolutions over the input layer are used to compute the output.\n",
    "+ This results in local connections, where each region of the input is connected to a neuron in the output. \n",
    "+ Each layer applies different filters and combines their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3933/3933 [==============================] - 1s 306us/step - loss: -8.4441\n",
      "CNN, Word Embeddings 0.33451957295373663\n"
     ]
    }
   ],
   "source": [
    "classifier = create_cnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print (\"CNN, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN  Recurrent Neural Network  LSTM\n",
    "\n",
    "+ Feed-forward neural networks in which activation outputs are propagated only in one direction, the activation #outputs from neurons propagate in both directions (from inputs to outputs and from outputs to inputs) in Recurrent #Neural Networks. Which creates loops in the neural network architecture which acts as a memory state of the neurons. This state #allows the neurons an ability to remember what have been learned so far.\n",
    "\n",
    "+ The memory state in RNNs gives an advantage over traditional neural networks but a problem called Vanishing Gradient #is associated with them. In this problem, while learning with a large number of layers, it becomes really hard for #the network to learn and tune the parameters of the earlier layers. \n",
    "\n",
    "+ To address this problem, A new type of RNNs called LSTMs (Long Short Term Memory) Models have been developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3933/3933 [==============================] - 7s 2ms/step - loss: -3.9096\n",
      "RNN-LSTM, Word Embeddings 0.33451957295373663\n"
     ]
    }
   ],
   "source": [
    " def create_rnn_lstm():\n",
    "\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_lstm()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print (\"RNN-LSTM, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - Gated Recurrent Units\n",
    "+ The Gated Recurrent Units are another form of recurrent neural networks.We will  add a layer of GRU instead of LSTM in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3933/3933 [==============================] - 10s 2ms/step - loss: -4.3614\n",
      "RNN-GRU, Word Embeddings 0.33451957295373663\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_gru():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the GRU Layer\n",
    "    lstm_layer = layers.GRU(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_gru()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print (\"RNN-GRU, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN\n",
    "+ RNN layers can be wrapped in Bidirectional layers as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3933/3933 [==============================] - 14s 3ms/step - loss: -9.7387\n",
      "RNN-Bidirectional, Word Embeddings 0.33451957295373663\n"
     ]
    }
   ],
   "source": [
    "def create_bidirectional_rnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_bidirectional_rnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print (\"RNN-Bidirectional, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Convolutional Neural Network\n",
    "\n",
    "As the essential architectures have been tried out, We can try different variants of these layers such as recurrent convolutional neural network. Another variants can be:\n",
    "\n",
    "- Hierarichial Attention Networks\n",
    "\n",
    "- Sequence to Sequence Models with Attention\n",
    "\n",
    "- Bidirectional Recurrent Convolutional Neural Networks\n",
    "\n",
    "- CNNs and RNNs with more number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3933/3933 [==============================] - 1s 321us/step - loss: -10.6859\n",
      "CNN, Word Embeddings 0.33451957295373663\n"
     ]
    }
   ],
   "source": [
    "def create_rcnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "    \n",
    "    # Add the recurrent layer\n",
    "    rnn_layer = layers.Bidirectional(layers.GRU(50, return_sequences=True))(embedding_layer)\n",
    "    \n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rcnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print (\"CNN, Word Embeddings\",  accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Generate Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLP pkgs\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Tokenize\n",
    "def custom_tokenizer(data):\n",
    "    mytokens = word_tokenize(data)\n",
    "    filtered_sent = [ w for w in mytokens if not w in stop_words]\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Generate vectors file tf-idf based vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tf-idf based vectors\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True, max_features = 500000)\n",
    "\n",
    "# Fit the model\n",
    "tf_transformer = tf.fit(df['Details'])\n",
    "\n",
    "# Dump the file\n",
    "pickle.dump(tf_transformer, open(\"tfidf1.pkl\", \"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-6ee76dc7ea35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m tf1_new = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True,\n\u001b[1;32m      6\u001b[0m                           max_features = 500000, vocabulary = tf1.vocabulary_)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_tf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf1_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "tf1 = pickle.load(open(\"tfidf1.pkl\", 'rb'))\n",
    "\n",
    "# Create new tfidfVectorizer with old vocabulary\n",
    "tf1_new = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True,\n",
    "                          max_features = 500000, vocabulary = tf1.vocabulary_)\n",
    "X_tf1 = tf1_new.fit_transform(new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "df = pd.read_csv(\"Main_Reshaped_Dataset.csv\")\n",
    "reader = (df['Details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\"))\n",
    "    for word in row[2].lower().split()]\n",
    "    for row in reader]    \n",
    "  #Removes header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-3514072d5d30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mreviewTFDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviewTFDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mreviewTFDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtfDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tfDict' is not defined"
     ]
    }
   ],
   "source": [
    "  def computeReviewTFDict(review):\n",
    "    \"\"\" Returns a tf dictionary for each review whose keys are all \n",
    "    the unique words in the review and whose values are their \n",
    "    corresponding tf.\n",
    "    \"\"\"\n",
    "    #Counts the number of times the word appears in review\n",
    "    reviewTFDict = {}\n",
    "    for word in review:\n",
    "        if word in reviewTFDict:\n",
    "            reviewTFDict[word] += 1\n",
    "        else:\n",
    "            reviewTFDict[word] = 1\n",
    "    #Computes tf for each word           \n",
    "    for word in reviewTFDict:\n",
    "        reviewTFDict[word] = reviewTFDict[word] / len(review)\n",
    "    return reviewTFDict\n",
    "tfDict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-474f0f474c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Stores the review count dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcountDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeCountDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-474f0f474c5e>\u001b[0m in \u001b[0;36mcomputeCountDict\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mcountDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Run through each review's tf dictionary and increment countDict's (word, doc) pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtfDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfDict' is not defined"
     ]
    }
   ],
   "source": [
    "  def computeCountDict():\n",
    "    \"\"\" Returns a dictionary whose keys are all the unique words in\n",
    "    the dataset and whose values count the number of reviews in which\n",
    "    the word appears.\n",
    "    \"\"\"\n",
    "    countDict = {}\n",
    "    # Run through each review's tf dictionary and increment countDict's (word, doc) pair\n",
    "    for review in tfDict:\n",
    "        for word in review:\n",
    "            if word in countDict:\n",
    "                countDict[word] += 1\n",
    "            else:\n",
    "                countDict[word] = 1\n",
    "    return countDict\n",
    "\n",
    "  #Stores the review count dictionary\n",
    "  countDict = computeCountDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(doc):\n",
    "    return {\n",
    "        token: True\n",
    "        for token in doc\n",
    "    }\n",
    "\n",
    "vectors = map(vectorize, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-9df93ed2ee7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfreq\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0monehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1058\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                                tokenize)\n\u001b[1;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 352\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "freq   = CountVectorizer()\n",
    "corpus = freq.fit_transform(corpus)\n",
    "\n",
    "onehot = Binarizer()\n",
    "corpus = onehot.fit_transform(corpus.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-31aa568c7957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m vectors = [\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Construct (word, frequency) mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-2f4744ead6d4>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "corpus  = [tokenize(doc) for doc in corpus]\n",
    "id2word = gensim.corpora.Dictionary(corpus)\n",
    "vectors = [\n",
    "    [(token[0], 1) for token in id2word.doc2bow(doc)]\n",
    "    for doc in corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
